import{_ as i,c as s,o as a,a1 as t}from"./chunks/framework.jky4UErf.js";const e="/llmops-docs/assets/flow.Bfv_AgSO.jpg",E=JSON.parse('{"title":"Prompt","description":"","frontmatter":{"outline":"deep"},"headers":[],"relativePath":"guide/langchain/prompt.md","filePath":"guide/langchain/prompt.md"}'),p={name:"guide/langchain/prompt.md"},l=t('<h1 id="prompt" tabindex="-1">Prompt <a class="header-anchor" href="#prompt" aria-label="Permalink to &quot;Prompt&quot;">​</a></h1><p>大多数 LLM 应用程序都不会直接将用户输入传递给 LLM ， 通常它们会将用户输入添加到一个更大的文本片段中，称为<strong>提示模板</strong></p><p><img src="'+e+`" alt="alt"></p><h2 id="prompt基本组成" tabindex="-1">Prompt基本组成 <a class="header-anchor" href="#prompt基本组成" aria-label="Permalink to &quot;Prompt基本组成&quot;">​</a></h2><p>Prompt 分为两大类</p><ul><li>Prompt Template：将 Prompt 按照 template 进行一定格式化，针对 Prompt 进行变量处理以及提示词的组合。</li><li>Selectors：根据不同条件去选择不同提示词，或者在不同情况下通过 Selector，选择不同示例去进一步提高 Prompt 支持能力。(本质上 Selectors 只是 Prompt Template 的二次封装)</li></ul><p>不同 Prompt 组件功能的简介：</p><ul><li><code>PromptTemplate</code>：用于创建文本消息提示模板，用于用于与大语言模型/文本生成模型进行交互。</li><li><code>ChatPromptTemplate</code>：用于创建聊天消息提示模板，一般用于与聊天模型进行交互。</li><li><code>MessagePlaceholder</code>：消息占位符，在聊天模型中对不确定是否需要的消息进行占位。</li><li><code>SystemMessagePromptTemplate</code>：用于创建系统消息提示模板，角色为系统。</li><li><code>HumanMessagePromptTemplate</code>：用于创建人类消息提示模板，角色为人类。</li><li><code>AIMessagePromptTemplate</code>：用于创建AI消息提示模板，角色为AI。</li><li><code>PipelinePromptTemplate</code>：用于创建管道消息，管道消息可以将提示模板作为变量进行快速复用。</li></ul><p>Prompt 不同方法的功能简介：</p><ul><li>partial：用于格式化提示模板中的部分变量。</li><li>format：传递变量数据，格式化提示模板为文本消息。</li><li>invoke：传递变量数据，格式化提示模板为提示。</li><li>to_string：将提示/消息提示列表转换成字符串。</li><li>to_messages：用于将提示转换成消息列表。</li></ul><h2 id="基础用法" tabindex="-1">基础用法 <a class="header-anchor" href="#基础用法" aria-label="Permalink to &quot;基础用法&quot;">​</a></h2><div class="language-py vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">py</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_core.prompts </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PromptTemplate</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">prompt_template </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PromptTemplate.from_template(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;将一个关于</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{topic}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">的笑话&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">prompt_template.invoke({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;topic&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;程序员&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># text=&#39;将一个关于程序员的笑话&#39;</span></span></code></pre></div>`,12),o=[l];function n(r,h,m,d,c,k){return a(),s("div",null,o)}const _=i(p,[["render",n]]);export{E as __pageData,_ as default};
